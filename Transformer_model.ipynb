{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPewKcnFRWQTCS6+10FB5uS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "exW6CsPD5TdZ",
        "outputId": "b6bac286-ae8e-45c3-c276-2c1c39a7a2b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a9e0fcc209e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mdataset_24h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBitcoinDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPREDICTION_HORIZON_24H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mdataset_1week\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBitcoinDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPREDICTION_HORIZON_1WEEK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-a9e0fcc209e0>\u001b[0m in \u001b[0;36mfetch_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Calculate Technical Indicators:cite[1]:cite[2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mbtc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RSI'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mbtc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MACD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmacd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MACD_12_26_9'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mbtc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VWAP'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvwap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVolume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mbtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import pandas_ta as ta\n",
        "from transformers import pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEQ_LEN = 60  # Input sequence length (1 hour)\n",
        "PREDICTION_HORIZON_24H = 24\n",
        "PREDICTION_HORIZON_1WEEK = 168\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 1. Data Loading & Preprocessing\n",
        "def fetch_data():\n",
        "    # Fetch Bitcoin historical data\n",
        "    btc = yf.download('BTC-USD', start='2023-03-25', end='2025-01-24', interval='1h')\n",
        "\n",
        "    # Calculate Technical Indicators:cite[1]:cite[2]\n",
        "    btc['RSI'] = ta.rsi(btc.Close, length=14)\n",
        "    btc['MACD'] = ta.macd(btc.Close, fast=12, slow=26, signal=9)['MACD_12_26_9']\n",
        "    btc['VWAP'] = ta.vwap(btc.High, btc.Low, btc.Close, btc.Volume)\n",
        "    btc = btc.dropna()\n",
        "\n",
        "    # Simulated Sentiment Data (Replace with real API calls):cite[7]:cite[8]\n",
        "    sentiment_model = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "    sample_texts = [\"Bitcoin will skyrocket!\", \"Market crash incoming\"] * 1000  # Mock data\n",
        "    sentiments = [sentiment_model(text[:512])[0]['score'] for text in sample_texts[:len(btc)]]\n",
        "    btc['Sentiment'] = sentiments[:len(btc)]  # Align length\n",
        "\n",
        "    return btc\n",
        "\n",
        "# 2. Dataset Preparation\n",
        "class BitcoinDataset(Dataset):\n",
        "    def __init__(self, data, seq_len, pred_horizon):\n",
        "        self.scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        self.data = self.scaler.fit_transform(data[['Close', 'RSI', 'MACD', 'VWAP', 'Sentiment']])\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_horizon = pred_horizon\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len - self.pred_horizon\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx:idx+self.seq_len]\n",
        "        y = self.data[idx+self.seq_len:idx+self.seq_len+self.pred_horizon, 0]  # Predict Close price\n",
        "        return torch.FloatTensor(x).to(device), torch.FloatTensor(y).to(device)\n",
        "\n",
        "# 3. Transformer Model Architecture\n",
        "class BitcoinTransformer(nn.Module):\n",
        "    def __init__(self, input_dim=5, d_model=128, nhead=4, num_layers=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, d_model)\n",
        "        self.pos_encoder = nn.TransformerEncoderLayer(d_model, nhead, dropout=dropout)\n",
        "        self.transformer = nn.TransformerEncoder(self.pos_encoder, num_layers=num_layers)\n",
        "        self.decoder = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(1, 0, 2)  # (seq_len, batch, d_model)\n",
        "        x = self.transformer(x)\n",
        "        x = x.permute(1, 0, 2)  # (batch, seq_len, d_model)\n",
        "        x = self.decoder(x[:, -1, :])  # Use last timestep for prediction\n",
        "        return x\n",
        "\n",
        "# 4. Training Loop\n",
        "def train_model(dataset, model, epochs=50):\n",
        "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# 5. Prediction & Visualization\n",
        "def predict_future(model, dataset, steps):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = dataset[-SEQ_LEN:][None, ...]  # Last sequence\n",
        "        preds = []\n",
        "        for _ in range(steps):\n",
        "            pred = model(torch.FloatTensor(x).to(device))\n",
        "            preds.append(pred.cpu().numpy())\n",
        "            x = np.roll(x, -1, axis=1)\n",
        "            x[:, -1, 0] = pred.item()  # Update Close price\n",
        "        return dataset.scaler.inverse_transform(np.array(preds).reshape(-1, 1))\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    data = fetch_data()\n",
        "    dataset_24h = BitcoinDataset(data, SEQ_LEN, PREDICTION_HORIZON_24H)\n",
        "    dataset_1week = BitcoinDataset(data, SEQ_LEN, PREDICTION_HORIZON_1WEEK)\n",
        "\n",
        "    # Initialize model\n",
        "    model = BitcoinTransformer().to(device)\n",
        "\n",
        "    # Train for 24h prediction\n",
        "    train_model(dataset_24h, model)\n",
        "    pred_24h = predict_future(model, dataset_24h, PREDICTION_HORIZON_24H)\n",
        "\n",
        "    # Train for 1-week prediction (adjust hyperparameters for longer horizons)\n",
        "    train_model(dataset_1week, model)\n",
        "    pred_1week = predict_future(model, dataset_1week, PREDICTION_HORIZON_1WEEK)\n",
        "\n",
        "    # Plot results\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(data['Close'].values[-500:], label='Historical Price')\n",
        "    plt.plot(np.arange(500, 500+PREDICTION_HORIZON_24H), pred_24h, label='24h Prediction')\n",
        "    plt.plot(np.arange(500, 500+PREDICTION_HORIZON_1WEEK), pred_1week, label='1-Week Prediction')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z_TG1Gf26oWJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}